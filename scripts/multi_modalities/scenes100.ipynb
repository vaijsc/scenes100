{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84e6e5-804a-4d1c-a3a9-89cd9cfc151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "import glob\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "import perspective2d.modeling  # noqa\n",
    "from perspective2d.utils.predictor import VisualizationDemo\n",
    "from perspective2d.config import get_perspective2d_cfg_defaults\n",
    "from perspective2d.utils import draw_perspective_fields, draw_from_r_p_f_cx_cy\n",
    "from perspective2d.utils.panocam import PanoCam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff945f-bf34-41e5-bd12-354b5d6a22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'paramnet_gsv_rpfpp' # 'paramnet_gsv_rpfpp'\n",
    "# MODEL_ID = 'paramnet_gsv_rpf'\n",
    "model_zoo = {\n",
    "    # trained on GSV dataset, predicts Perspective Fields + camera parameters (roll, pitch, fov, principal point)\n",
    "    'paramnet_gsv_rpfpp': {\n",
    "        'weights': ['https://www.dropbox.com/s/ufdadxigewakzlz/paramnet_gsv_rpfpp.pth'],\n",
    "        'opts': ['MODEL.WEIGHTS', 'PerspectiveFields_models/paramnet_gsv_rpfpp.pth'],\n",
    "        'config_file': 'PerspectiveFields_models/paramnet_gsv_rpfpp.yaml',\n",
    "        'param': True,\n",
    "    },\n",
    "    # trained on GSV dataset, predicts Perspective Fields + camera parameters (roll, pitch, fov), assuming centered principal point\n",
    "    'paramnet_gsv_rpf': {\n",
    "        'weights': ['https://www.dropbox.com/s/g6xwbgnkggapyeu/paramnet_gsv_rpf.pth'],\n",
    "        'opts': ['MODEL.WEIGHTS', 'PerspectiveFields_models/paramnet_gsv_rpf.pth'],\n",
    "        'config_file': 'PerspectiveFields_models/paramnet_gsv_rpf.yaml',\n",
    "        'param': True,\n",
    "    },\n",
    "}\n",
    "assert MODEL_ID in model_zoo.keys()\n",
    "\n",
    "for html in model_zoo[MODEL_ID]['weights']:\n",
    "    if not os.path.exists(os.path.join('PerspectiveFields_models', html.split('/')[-1])):\n",
    "        !wget -P models/ {html}\n",
    "def setup_cfg(args):\n",
    "    cfgs = []\n",
    "    configs = args['config_file'].split('#')\n",
    "    weights_id = args['opts'].index('MODEL.WEIGHTS') + 1\n",
    "    weights = args['opts'][weights_id].split('#')\n",
    "    for i, conf in enumerate(configs):\n",
    "        if len(conf) != 0:\n",
    "            tmp_opts = copy.deepcopy(args['opts'])\n",
    "            tmp_opts[weights_id] = weights[i]\n",
    "            cfg = get_cfg()\n",
    "            get_perspective2d_cfg_defaults(cfg)\n",
    "            cfg.merge_from_file(conf)\n",
    "            cfg.merge_from_list(tmp_opts)\n",
    "            cfg.freeze()\n",
    "            cfgs.append(cfg)\n",
    "    return cfgs\n",
    "\n",
    "perspective_cfg_list = setup_cfg(model_zoo[MODEL_ID])\n",
    "demo_perspective = VisualizationDemo(cfg_list=perspective_cfg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d11e2c-6c98-413d-bde2-fef0e20dd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(net, img):\n",
    "    pred = net.run_on_image(img)\n",
    "#     print(pred)\n",
    "    if 'pred_general_vfov' not in pred.keys():\n",
    "        pred['pred_general_vfov'] = pred['pred_vfov']\n",
    "    if 'pred_rel_cx' not in pred.keys():\n",
    "        pred['pred_rel_cx'] = torch.FloatTensor([0])\n",
    "    if 'pred_rel_cy' not in pred.keys():\n",
    "        pred['pred_rel_cy'] = torch.FloatTensor([0])\n",
    "\n",
    "    r_p_f_rad = np.radians(\n",
    "        [\n",
    "            pred['pred_roll'].cpu().item(),\n",
    "            pred['pred_pitch'].cpu().item(),\n",
    "            pred['pred_general_vfov'].cpu().item(),\n",
    "        ]\n",
    "    )\n",
    "    cx_cy = [\n",
    "        pred['pred_rel_cx'].cpu().item(),\n",
    "        pred['pred_rel_cy'].cpu().item(),\n",
    "    ]\n",
    "#     print(f\"roll {pred['pred_roll'].cpu().item() :.2f}, pitch {pred['pred_pitch'].cpu().item() :.2f}, fov {pred['pred_general_vfov'].cpu().item() :.2f}\")\n",
    "#     print(f\"principal point {pred['pred_rel_cx'].cpu().item() :.2f} {pred['pred_rel_cy'].cpu().item() :.2f} \")\n",
    "    return r_p_f_rad, cx_cy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32574882-a357-42ec-bdcc-027dc540a401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_id_list = ['001', '003', '005', '006', '007', '008', '009', '011', '012', '013', '014', '015', '016', '017', '019', '020', '023', '025', '027', '034', '036', '039', '040', '043', '044', '046', '048', '049', '050', '051', '053', '054', '055', '056', '058', '059', '060', '066', '067', '068', '069', '070', '071', '073', '074', '075', '076', '077', '080', '085', '086', '087', '088', '090', '091', '092', '093', '094', '095', '098', '099', '105', '108', '110', '112', '114', '115', '116', '117', '118', '125', '127', '128', '129', '130', '131', '132', '135', '136', '141', '146', '148', '149', '150', '152', '154', '156', '158', '159', '160', '161', '164', '167', '169', '170', '171', '172', '175', '178', '179']\n",
    "calibrates = {}\n",
    "image_1st, r_p_f_rad_mean, center_mean = {}, {}, {}\n",
    "\n",
    "for video_id in video_id_list:\n",
    "    calibrates[video_id] = {}\n",
    "    images = sorted(glob.glob(os.path.join('/mnt/e/Datasets/Intersections/images/annotated/%s/unmasked' % video_id, '*.jpg')))\n",
    "    print('%s: %d images' % (video_id, len(images)))\n",
    "    images = [{'file_name': x, 'img':  read_image(x, format=\"BGR\")} for x in images]\n",
    "    calibrates[video_id]['image_1st'] = images[0]['img']\n",
    "    for img in images:\n",
    "        r_p_f_rad, cx_cy = calibrate(demo_perspective, img['img'])\n",
    "        img['r_p_f_rad'], img['cx_cy'] = r_p_f_rad, cx_cy\n",
    "    calibrates[video_id]['r_p_f_rad'], calibrates[video_id]['center'] = [], []\n",
    "    for img in images:\n",
    "        calibrates[video_id]['r_p_f_rad'].append(r_p_f_rad)\n",
    "        calibrates[video_id]['center'].append(cx_cy)\n",
    "    calibrates[video_id]['r_p_f_rad'] = np.stack(calibrates[video_id]['r_p_f_rad'], axis=0).mean(axis=0)\n",
    "    calibrates[video_id]['center'] = np.stack(calibrates[video_id]['center'], axis=0).mean(axis=0)\n",
    "    print(calibrates[video_id]['r_p_f_rad'], calibrates[video_id]['center'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6cfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizon_ratio(h, fov_h, pitch):\n",
    "    assert pitch - fov_h / 2 > -np.pi / 2\n",
    "    if pitch < 0:\n",
    "        if abs(pitch) > fov_h / 2:\n",
    "            return -1, np.cos(np.pi / 2 - abs(pitch) - fov_h / 2) / np.cos(np.pi / 2 - abs(pitch) + fov_h / 2)\n",
    "        else:\n",
    "            return int(h / 2 + np.tan(pitch) / np.tan(fov_h / 2) * h / 2), -1\n",
    "    else: # camera not likely points up, fall back to pitch=0\n",
    "        return int(h / 2), -1\n",
    "\n",
    "for video_id in video_id_list:\n",
    "    _, pitch, fov_diag = calibrates[video_id]['r_p_f_rad']\n",
    "    h, w, _ = calibrates[video_id]['image_1st'].shape\n",
    "    diag = (w ** 2 + h ** 2) ** 0.5\n",
    "    fov_w, fov_h = np.arctan(np.tan(fov_diag / 2) * w / diag) * 2, np.arctan(np.tan(fov_diag / 2) * h / diag) * 2\n",
    "    calibrates[video_id]['horizon'], calibrates[video_id]['ratio'] = get_horizon_ratio(h, fov_h, pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155a1b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_ratio, min_ratio = 3, 2\n",
    "\n",
    "for video_id in ['001', '019', '091', '016', '175', '036']:\n",
    "    horizon = calibrates[video_id]['horizon']\n",
    "    if horizon > 0:\n",
    "        im_upper, im_lower = calibrates[video_id]['image_1st'][:horizon, :, :], calibrates[video_id]['image_1st'][horizon:, :, :]\n",
    "        im_upper_unwarped = cv2.resize(im_upper, (int(im_upper.shape[1] * max_ratio), int(im_upper.shape[0] * max_ratio)), cv2.INTER_LINEAR)\n",
    "        h_lower, w_lower, _ = im_lower.shape\n",
    "        pt_corners = np.float32([[0, 0], [w_lower, 0], [w_lower, h_lower], [0, h_lower]])\n",
    "        pt_unwarp = np.float32([[0, 0], \\\n",
    "                                [w_lower * max_ratio, 0], \\\n",
    "                                [w_lower * (max_ratio + 1) / 2, h_lower * max_ratio / 2], \\\n",
    "                                [w_lower * (max_ratio - 1) / 2, h_lower * max_ratio / 2]])\n",
    "        M = cv2.getPerspectiveTransform(pt_corners, pt_unwarp)\n",
    "        im_lower_unwarped = cv2.warpPerspective(im_lower, M, \\\n",
    "                                                (int(w_lower * max_ratio), int(h_lower * max_ratio / 2)))\n",
    "        unwarped = np.concatenate([im_upper_unwarped, im_lower_unwarped], axis=0)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(unwarped); plt.axis('off'); plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        h, w, _ = calibrates[video_id]['image_1st'].shape\n",
    "        ratio = max(min_ratio, min(max_ratio, calibrates[video_id]['ratio']))\n",
    "        pt_corners = np.float32([[0, 0], [w, 0], [w, h], [0, h]])\n",
    "        pt_unwarp = np.float32([[0, 0], [w * ratio, 0], [w * (ratio + 1) / 2, h * ratio / 2], [w * (ratio - 1) / 2, h * ratio / 2]])\n",
    "        M = cv2.getPerspectiveTransform(pt_corners, pt_unwarp)\n",
    "        unwarped = cv2.warpPerspective(calibrates[video_id]['image_1st'], M, (int(w * ratio), int(h * ratio / 2)))\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(unwarped); plt.axis('off'); plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1ccd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
